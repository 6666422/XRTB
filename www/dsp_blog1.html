<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Do it yourself JAVA (DIY) DSP with RTB4FREE. We discuss the things you need to take into account when building your own DSP.">
    <meta name="keywords" content="DIY,DSP,SSP,Video,Banner,RTB,OpenRTB,JAVA,Advertising">
    <meta name="author" content="RTB4FREE">

    <title>DIY DSP - RTB4FREE</title>
   <link rel="shortcut icon" href="images/alien.png">

    <link href=
    "https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css"
    rel="stylesheet">
    <link href=
    "https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap-theme.min.css"
    rel="stylesheet">
    <script src=
    "https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <script src=
    "https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    
    <script type="text/javascript">

function toggle(elementId) {
	var ele = document.getElementById(elementId);
	if(ele.style.display == "block") {
    		ele.style.display = "none";
  	}
	else {
		ele.style.display = "block";
	}
} 
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-5532985-4', 'auto');
  ga('send', 'pageview');

</script>

  <body>
   
   
   <nav class="navbar navbar-fixed-top navbar-inverse">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">RTB 4 Free!</a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="index.html">Home</a></li>
            <li><a href="about.html">About</a></li>
            <li><a href="contact.html">Contact</a></li>
          </ul>
        </div><!-- /.nav-collapse -->
      </div><!-- /.container -->
    </nav><!-- /.navbar -->

<br>
<br>
<br>

    <div class="container">
    
<h2>Do It Yourself DSP Using RTB4FREE</h2>


<h3>The Overview of DSP Operations with RTB4FREE</h3>
<p>So now you have decided to build your own DSP. It all looks pretty do-able. But it is not as east to do as you think -  
it is an involved process and a lot of people get tripped up by the details. This blog post will introduce you  how to all the other
things it takes to build a DSP from the ground up with RTB4FREE. Later blog posts will set up an actual DSP using RTB4FREE.</p>

<p>There is more to a DSP than just running an RTB bidder. The bidder is important, 
but there are other important components. We will run through the basic pieces you will need here. 
To start with, we are presuming you are going to use Amazon AWS.</p>

<h3>What are your requirements?</h3>
<p>First, you need to know what are your requirements ahead of time. 
How many QPS are you going to need?. Are you going to store bid requests for post-analysis (you should)?
How much of this data are you going to store? What will your overhead costs be? Here is a laundry list of the costs involved:</p>
<ul>
<li>Instance costs.</li>
<li>Disk storage costs.</li>
<li>Long term storage costs.</li>
<li>Post-processing costs.</li>
<li>Cost of system management.</li>
<li>SSP charges.</li>
</ul>

<h3>Determining your basis cost</h3>
<p>Once you know the QPS requirements you can predict your instance and storage costs. 
Also, you will need other software and systems to manage, control and analyze RTB data and logs files.</p>
<p>System management is critical. You need to know if your 
instances are healthy, that the CPU utilization, disk space, network connections are alive healthy and manageable. 
We can't provide this software and capability for you, you need to set this up yourself. And note, you will need to 
move the stored bid request data from the bidder instances periodically to make sure you don't run out of disk space.
You can monitor your instance bidder log files with something like ElasticSearch or Splunk, or use tools available on Hadoop</p>
<p>As you save the bid request data you will be storing huge amounts of data. How relevant all of it is to you and how
much to keep is something you have to determine yourself. But, disk storage easily is the lion's share of the cost. 
In fact, at 5K QPS 24/7 operation, your AWS costs will approach $5,000.00 per month, $3,500.00 of that will be disk storage, 
to keep just 30 days of data for post processing.</p>

<h3>Other software components you will need</h3>
As mentioned there are a lot of other software components you will need to run a DSP. This isn't a complete list, 
but these are certainly critical must haves:</p>
<ul>
<li>Systems management software.
<p>At a bare minimum you need to closely  watch CPU utilization, free disk space, and the bid response tim of the bidders responding
to processing campaigns. Bid times shouldn't exceed 50ms. All of these metrics are reported in /var/log/rtb4free.log once a minute. You will set up your monitoring software to watch
for this.</p></li>

<li>Campaign management software
<p>RTB4FREE does not use a database for campaign management. We don't want to dictate the requirement to use
MySQL, Oracle, Mongodb, Hive, etc. Instead, campaigns are stored in REDIS, using JAVA REDISSON for 
the bidders to use. You have to create the REDISSON objects for Campaigns and then tell the bidders using a REDIS Publish command 
tell the bidders to load new or changed campaigns. This is not hard to implement. In any case we provide a separate JDBC based JAVA
program that works with SQL to create campaigns and maintain accounting data -  called Crosstalk.</p></li>

<p>Crosstalk is a set of SQL tables and a JAVA program that will push campaigns out ro REDIS/REDISSON in the proper format
and then load them into. the bidders. Crosstalk handles all the normal campaign management things like the
master black-list, white-lists, constraint checking and frequency capping. Crosstalk also keeps up with the auctions 
per campaign and impression and adds up charges, and makes sure the campaigns don't exceed budgets, including daily budgets. 
Or you can write your own interface to REDIS/REDISSON, using Crosstalk as a starting point. We support Crosstalk, but if you modify it, it's your responsibility 
to keep it updated and running.</p></li>

<li>Post processing of bid request data.
<p> The bid request data is valuable. You can get an excellent idea of what the SSP's publishers have to sell, but you need
analysis software capable of reading JSON data and that provides a query capability on that data.
You will need this data to create white lists AND WHITE LISTS ARE VERY IMPORTANT. If you don't white list, 
you will bid on a lot of garbage impressions.</p>

<p>The bid request data is a “Big Data” problem. There is a lot of it, and it grows rapidly. But you need this 
data to ensure your campaigns work in the eco system. Are you using the best banner sizes? Where are the bid 
requests originating from? What devices are being used? Do my IAB categories match? All of the answers are in the data. But you need
the ability to store it, load it and query it.</p>

<p>Splunk and ElasticSearch are good tools for looking at the bid request data, and each has powerful query capabilities 
that can give you insight into the market you are trying to purchase ad space.</p></li>
</ul>

<h3>Data Management Plan.</h3>
<p>How much data will you store, how will you get at it? Are you going to store in Glaciar, in Hadoop? Cassandra? 
As simple flat files? Your analysis will depend on the proper implementation of a good data management plan.</p>
<p>Bid requests can be stored on each bidder in the XRTB/logs/request file. This file grows very quickly. You need  to move this data 
off the bidder and into your repository frequently, at least once an hour into your repository.</p>
<p>If you are using Splunk or ElasticSearch you then need to move this data into their repository. If you are using Hadoop you need to
move it into Hadoop's file system. These are all processes you need to implement.
</p></li>

<h3>Exchange (SSP) connections</h3>
<p>The SSPs will connect to you with hundreds of connections per 100 QPS you ask for. Make sure your instances 
are large enough to handle this and your instances are tuned for large amounts of WEB traffic. Out of the box, 
AWS Ubuntu instances are not tuned right for this.</p>
<p>Also, you need to make sure you are not processing QPS for no good reason. If you are running no campaigns, turn your connection to
the SSP off. Or, simply stop your instances if the SSP gracefully degrades the connections to you if the a

<h3>Campaign Management</h3>

<p>Obviously this is critical part of RTB. But before you begin bidding, run the bidders for a while and just store
the bid requests, but NO-BID on everything.. Do this for several days. Then analyze ther bid request data to see what is
actually available out there to bid on.</p>
<p>It is a big mistake to not know what is out there in the data stream. What domains are most prevalent? What are the ad sizes most
frequently requested. What IAB categories are the interesting domains interested in? Do the device records in the bid request data
have GEO tags? Does the user object have age and gender information?</p>
<p>The simplest mistake is choosing the wrong ad-sizes. People make simple mistakes and can't understand why their bidders are not 
bidding on anything. If your banner sizes aren't being requested by the publishers, you won't make any bids. There are standard sizes, and 
the most common being 320x50. Make sure your impression size is relevant</p>
<p>If your campaign isn't bidding analyze the bid request data. Use Splunk or ElasticSearch to see why using a query on the
dataset that matches your campaign. Obviously if 
none of the bid requests from the SSP match your campaigns, you aren't going to bid</p>

<p>Know your bid request data! Just because a bid request comes in, and the bid request parameters meet your constraints that
doesn't mean you should bid on it. There are a lot of bad actors out there publishing garbage web sites specifically to lure you
onto a page that has hundreds of ads per page, or your impressions could be loading into BOTs. You need to take proactive action
to protect your ad dollars. Here are some things to consider.</p>
<ul>
<li>White listing.
<p>White listing is a list of publishers that you will bid on, and nobody else. 
These are advertisers you trust. Believe it or not, the SSPs sell a ton of garbage impressions from garbage sites. 
You don't want to bid on a site where the page has 20 other ads on it, no? Know your seller if you can.</p></li>
<li>Black listing.
<p>Black listing is the reverse of white listing. These are a list of advertisers you won't buy from, for
 whatever reason. If you don't white-list you should at least black list. Over time, after losing money you will know 
 who these sites are.</p>
<p>You need your post data analysis here. Look for those sites where you bought a lot of impressions and got no clicks, 
or you got clicks but no impressions. In the case of no clicks, these are likely click-bait sites with lots of ads 
on every page. You get lost on the page. The no conversions likely means BOTs.</p>

<p>The SSPs talk a good game about transparency and spread a lot of  buzz-words spouting quality, but in the end they have no 
problem presenting  click-bait sites to you or exposing you to BOTnets faking clicks. This problem is rampant. 
Probably 50% of all ad traffic on the Internet is fake.</p></li>

<li>BOT Protection.
<p>The best way to protect yourself from BOTs is to get a Forensiq account. 
It's not free, but it costs less than presenting impressions to click BOTs. RTB4FREE is 
already set up to use Forensiq.</p></li>


<li>High quality Web Publisher detection.
<p> We don't know how to do this, if we did, we would be millionaires. 
But you need to periodically go back over your click data and the bid requests and find those sites that are high 
quality. Maybe you should manually click on some sites presented in the bid requests to see exactly what impressions 
are being offered. If the page has more than 5 ads on it, maybe you shouldn't bid on that page. This is a value judgment.</p>

<p>We can't tell you how many times we have clicked on a publisher's site and been hit with a spear phishing campaign, 
or is a page with 1000 ads on it. Clearly fraud. But the SSPs can't catch them all, and some don't care and don't even try.</p>

<p>Use white lists if you can, and blaclist as you go if you don't . Don't blindly bid, you will lose money.</p>
</li>

<li>Ensure your SSP has the publishers that can make you money.
<p>The nightmare: now you are connected to your SSP and you 
are bidding away. But you aren't making making many conversions…. Now what do you do?</p>

<p>You go back and look at the variety of publishers the SSP has for you – and you find 80% of the 
traffic is from 6 publishers. Guess what, you won't make any money there. One time, 
this actually happened. And those 6 sites were all gossip, soft-core porn and celebrity 
sites. And the advertiser was trying to protect his brand. Obviously this was a big mismatch, 
not to mention the SSP really had nothing to offer of value.</p>

<p>But you won't know if you don't know your bid request data. The easier it is to analyze the bid request data, 
the better prepared you are to make the proper judgments.</p></li>
</ul>

<h3>Performance Issues</h3>
<p>You will be setting your bidders up behind a load balancer. 
The more QPS you need, the more bidders you start. As your QPS  needs decline, shut down bidders – 
so you don't pay for instance charges you don't need.</p>

<p>Between 11PM and 5AM you probably don't need to bid that much, and guess what, the BOTs never 
sleep and BOT traffic is more prevalent at night as other advertisers go off-line for the night.</p>

<p>We reiterate the need for performance measurement of the /var/log/rtb4free.log files on the instances
 you are running. As bid times increase beyond 40ms per second, start more instances, as the bid times 
 decrease, consider stopping the instance(s) you don't need. But you need to measure to know what is going on</p>

<p>If you can tie all of this in with auto-scale, that's all the better.</p>

<h3>Affiliate Issues</h3>
If you are buying ads for affiliates beware. Do you what they are advertising, Several companies we know opened their
DSP to the public to he;p utilize the SSP inventory. Only to find that the affiliates are pumping low quality ads out, and
engaging in phishing scams and delivering pornography. All of these things hurt your reputation with the SSP, and can even get
your account cancelled.</p>
<p>As a result, several of these DSPs that were once open to the public are now closed. Policing the affiliates just became too 
much of a headache.</p>
<p>In the end, nnow what you are offering on the network, it's your SSP account, but your affiliate's 
ad. Don't get your account canceled because you didn't know an affiliate was injecting malware into their ads. It happens all the time….</p>

<br/>
       <footer>
        <p>&copy; Ben M. Faul, Peter Loh, RTB4FREE.ORG 2016<br/>Email: Ben.Faul@gmail.com</p>
      </footer>
    
</div>
</html>